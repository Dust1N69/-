{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4955c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "75081069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d99a8488",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d6a08787",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'Administrative',\n",
    "    'Informational',\n",
    "    'ProductRelated',\n",
    "    'PageValues',\n",
    "    'BounceRates',\n",
    "    'ExitRates',\n",
    "    'Month',\n",
    "    'VisitorType',\n",
    "    'Weekend',\n",
    "    'TrafficType'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0ac23078",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[selected_features].copy()\n",
    "y = train_df['Revenue']\n",
    "X_test = test_df[selected_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "096d04fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['Month', 'VisitorType', 'Weekend', 'TrafficType']\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "numeric_cols = [col for col in selected_features if col not in categorical_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef188f0f",
   "metadata": {},
   "source": [
    "建立columnTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4d4a02dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), numeric_cols),\n",
    "    \n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07681a3",
   "metadata": {},
   "source": [
    "建模&訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "02ab2d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: AUC = 0.8686, Accuracy = 0.8778\n",
      "Random Forest: AUC = 0.9160, Accuracy = 0.8975\n",
      "XGBoost: AUC = 0.9111, Accuracy = 0.8864\n",
      "[LightGBM] [Info] Number of positive: 1022, number of negative: 5458\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1041\n",
      "[LightGBM] [Info] Number of data points in the train set: 6480, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.157716 -> initscore=-1.675321\n",
      "[LightGBM] [Info] Start training from score -1.675321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\airbnb\\.conda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:18:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM: AUC = 0.9195, Accuracy = 0.8907\n",
      "\n",
      " Best Model: LightGBM (AUC = 0.9195)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\airbnb\\.conda\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "best_auc = -1\n",
    "best_model = None\n",
    "best_name = \"\"\n",
    "\n",
    "## 7. 分割訓練/驗證\n",
    "X_train_raw, X_val_raw, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 8. 訓練與評估模型\n",
    "results = {}\n",
    "best_model = None\n",
    "best_auc = -1\n",
    "best_name = \"\"\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    pipe.fit(X_train_raw, y_train)\n",
    "    val_probs = pipe.predict_proba(X_val_raw)[:, 1]\n",
    "    \n",
    "    auc = roc_auc_score(y_val, val_probs)\n",
    "    acc = accuracy_score(y_val, val_probs > 0.5)\n",
    "    results[name] = {\"AUC\": auc, \"Accuracy\": acc}\n",
    "    \n",
    "    print(f\"{name}: AUC = {auc:.4f}, Accuracy = {acc:.4f}\")\n",
    "    \n",
    "    if auc > best_auc:\n",
    "        best_auc = auc\n",
    "        best_model = pipe\n",
    "        best_name = name\n",
    " \n",
    "print(f\"\\n Best Model: {best_name} (AUC = {best_auc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "39712a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\airbnb\\.conda\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1277, number of negative: 6823\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1111\n",
      "[LightGBM] [Info] Number of data points in the train set: 8100, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.157654 -> initscore=-1.675786\n",
      "[LightGBM] [Info] Start training from score -1.675786\n",
      "預測完成，輸出檔案：my_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# 訓練完的模型變數\n",
    "final_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', models[best_name])\n",
    "])\n",
    "final_model.fit(X, y)  # 使用完整訓練資料進行訓練\n",
    "\n",
    "# 預測完的儲存變數\n",
    "test_probs = final_model.predict_proba(X_test)[:, 1]  # 預測消費的機率\n",
    "\n",
    "# 將預測結果寫入 CSV，並按照 ID 排序\n",
    "submission_df = test_df[['ID']].copy()  # 確保與 test.csv 的 ID 一致\n",
    "submission_df['HasRevenue'] = test_probs  # 儲存預測機率\n",
    "submission_df = submission_df.sort_values('ID', ascending=True)  # 按 ID 排序\n",
    "submission_df.to_csv('my_submission1.csv', index=False)  # 輸出 CSV 檔案\n",
    "\n",
    "print(\"預測完成，輸出檔案：my_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "21717708",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (8100, 1), indices imply (8100, 45)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[125]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m final_feature_names = numeric_cols + \u001b[38;5;28mlist\u001b[39m(cat_feature_names)\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# 建立 DataFrame 並加上標籤欄\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m train_cleaned_df = pd.DataFrame(X_cleaned, columns=final_feature_names)\n\u001b[32m     31\u001b[39m train_cleaned_df[\u001b[33m'\u001b[39m\u001b[33mRevenue\u001b[39m\u001b[33m'\u001b[39m] = y.values\n\u001b[32m     33\u001b[39m test_cleaned_df = pd.DataFrame(X_test_cleaned, columns=final_feature_names)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\airbnb\\.conda\\Lib\\site-packages\\pandas\\core\\frame.py:867\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    859\u001b[39m         mgr = arrays_to_mgr(\n\u001b[32m    860\u001b[39m             arrays,\n\u001b[32m    861\u001b[39m             columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    864\u001b[39m             typ=manager,\n\u001b[32m    865\u001b[39m         )\n\u001b[32m    866\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m867\u001b[39m         mgr = ndarray_to_mgr(\n\u001b[32m    868\u001b[39m             data,\n\u001b[32m    869\u001b[39m             index,\n\u001b[32m    870\u001b[39m             columns,\n\u001b[32m    871\u001b[39m             dtype=dtype,\n\u001b[32m    872\u001b[39m             copy=copy,\n\u001b[32m    873\u001b[39m             typ=manager,\n\u001b[32m    874\u001b[39m         )\n\u001b[32m    875\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    876\u001b[39m     mgr = dict_to_mgr(\n\u001b[32m    877\u001b[39m         {},\n\u001b[32m    878\u001b[39m         index,\n\u001b[32m   (...)\u001b[39m\u001b[32m    881\u001b[39m         typ=manager,\n\u001b[32m    882\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\airbnb\\.conda\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:336\u001b[39m, in \u001b[36mndarray_to_mgr\u001b[39m\u001b[34m(values, index, columns, dtype, copy, typ)\u001b[39m\n\u001b[32m    331\u001b[39m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[32m    332\u001b[39m index, columns = _get_axes(\n\u001b[32m    333\u001b[39m     values.shape[\u001b[32m0\u001b[39m], values.shape[\u001b[32m1\u001b[39m], index=index, columns=columns\n\u001b[32m    334\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m _check_values_indices_shape_match(values, index, columns)\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\airbnb\\.conda\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[39m, in \u001b[36m_check_values_indices_shape_match\u001b[39m\u001b[34m(values, index, columns)\u001b[39m\n\u001b[32m    418\u001b[39m passed = values.shape\n\u001b[32m    419\u001b[39m implied = (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Shape of passed values is (8100, 1), indices imply (8100, 45)"
     ]
    }
   ],
   "source": [
    "\n",
    "# 先定義數值與類別欄位\n",
    "categorical_cols = ['Month', 'VisitorType', 'Weekend', 'TrafficType']\n",
    "numeric_cols = [col for col in selected_features if col not in categorical_cols]\n",
    "\n",
    "# 建立前處理器\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), numeric_cols),\n",
    "    \n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]), categorical_cols)\n",
    "])\n",
    "\n",
    "# 擬合並轉換訓練與測試資料\n",
    "X_cleaned = preprocessor.fit_transform(X)\n",
    "X_test_cleaned = preprocessor.transform(X_test)\n",
    "\n",
    "# 取得經 OneHotEncoder 編碼後的欄位名稱\n",
    "ohe = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "cat_feature_names = ohe.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# 合併所有欄位名稱\n",
    "final_feature_names = numeric_cols + list(cat_feature_names)\n",
    "\n",
    "# 建立 DataFrame 並加上標籤欄\n",
    "train_cleaned_df = pd.DataFrame(X_cleaned, columns=final_feature_names)\n",
    "train_cleaned_df['Revenue'] = y.values\n",
    "\n",
    "test_cleaned_df = pd.DataFrame(X_test_cleaned, columns=final_feature_names)\n",
    "\n",
    "# 匯出為 CSV\n",
    "train_cleaned_df.to_csv(\"train_cleaned.csv\", index=False)\n",
    "test_cleaned_df.to_csv(\"test_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"✅ 匯出完成：train_cleaned.csv 與 test_cleaned.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
